# Queryosity Killed the RAG

<div align="center">
  <img src="assets/thumbnail.png" alt="Queryosity Hero" width="600"/>
</div>

## ğŸš€ Smarter Enterprise Search with BigQuery

A full-stack application for BQ Competition 2025 featuring AI agents (Google-ADK), React frontend, and BigQuery Storage and AI for SEC filings analysis and contract processing.

This solution, built entirely on BigQuery and Google Cloud, reduces the time it takes to find, filter, and understand enterprise documents. Instead of treating each document as a blob of text, we parse and enrich files into a semi-structured schema: agreement type, key entities (company, parties), dates, jurisdiction, a summary of the document.

This allows documents to be queried directly with SQL, joined with existing enterprise datasets. For complex questions, we seamlessly layer in AI.GENERATE , AI.GENERATE_TABLE and AI.GENERATE_BOOL, with OBJECTREFs enabling tasks like sentiment analysis, clause filtering, and any AI parsing we have, all without leaving BigQuery.

### ğŸ¯ Example Use Case
**Query**: *"Get me all the loan agreements of Tesla and derive their interest rates."*

1. ğŸ” Gets documents where `company_name` is like '%Tesla%'
2. ğŸ¤– Uses `AI.GENERATE` to extract interest rates using `OBJECTREF`

<div align="center">
  <img src="assets/slide.png" alt="Solution Overview" width="700"/>
  <p><em>Solution Overview - From Unstructured Data Silos -> BigQuery Powered Search</em></p>
</div>

### ğŸŒŸ Impact
The impact is broad: 
- **Legal teams** can instantly locate contracts with specific obligations
- **Compliance teams** can track renewal clauses
- **HR teams** can search employment agreements  
- **Finance teams** can analyze obligations across invoices

In short, any enterprise with unstructured data can connect their storage to BigQuery and immediately turn it into a structured knowledge base.

Anyone who is a part of the organization can use BigQuery, without being skilled in actually writing queries.

> **ğŸ’¡ BigQuery is the engine, Agent is our waymo, we just tell it what to search.**

## ğŸ“‹ Overview

<div align="center">
  <img src="assets/Architecture.png" alt="System Architecture" width="800"/>
  <p><em>System Architecture Overview</em></p>
</div>

This project analyzes SEC contract data using BigQuery's AI/ML capabilities to transform unstructured contract documents into structured, queryable insights. Which includes ObjectRefs to enable AI Functions on the Fly.

## âœ¨ Key Features

- ğŸ” **Intelligent Document Processing**: Parse contracts into structured data using Gemini AI
- ğŸ—„ï¸ **BigQuery Native**: Store and query documents directly in BigQuery with SQL
- ğŸ¤– **AI-Powered Analysis**: Leverage `AI.GENERATE`, `AI.GENERATE_TABLE`, and `AI.GENERATE_BOOL` functions
- ğŸ”— **ObjectRef Integration**: Enable multimodal analysis and on-the-fly AI processing
- ğŸŒ **Interactive Web Interface**: Chat-based interface for natural language querying
- ğŸ“Š **Real-time Analytics**: Join document data with existing enterprise datasets
- ğŸš€ **Scalable Architecture**: Built on Google Cloud for enterprise-scale processing 

### ğŸ“Š Dataset

The project uses the [Material Contract Corpus](https://mcc.law.stanford.edu/download/contracts/) from Stanford University - a comprehensive dataset containing over 1M contract documents from 2000-2023, with a focus on 2020-2023 data (130k+ documents). The dataset has been uploaded to Google Cloud Storage for processing.

### ğŸ”„ Data Processing Pipeline

1. **ğŸ“¥ Ingestion** (`src/ingestion/`): Contract documents with a subset of 2020/Q1 documents were processed using Google's Gemini AI to extract structured data including company names, contract types, governing law, parties involved, and key clauses.
   - `extraction.py`: Main extraction script that processes files from Google Cloud Storage
   - `contract_schema.py`: Defines the Pydantic models and BigQuery schema for extracted contract data

2. **ğŸ—„ï¸ BigQuery Storage**: Extracted data is stored in BigQuery tables with a comprehensive schema supporting advanced analytics and AI-powered querying.

3. **ğŸ¤– AI/ML Integration**: The system leverages BigQuery's built-in AI functions (`AI.GENERATE`, `AI.GENERATE_TABLE`) for intelligent contract analysis and natural language querying.
   - `notebooks/BQ-MCC-EXPLORATION.ipynb`: Exploration on how to use BigQuery AI/ML capabilities
   - `notebooks/objectRef.ipynb`: Shows how to include multimodal analysis with BigQuery object referencing and AI/ML integration

## ğŸ—ï¸ Components

### ğŸ““ Notebooks
Interactive Jupyter notebooks demonstrating BigQuery AI/ML capabilities:
- `BQ-MCC-EXPLORATION.ipynb`: Explores the Material Contract Corpus data and BigQuery AI/ML features
- `objectRef.ipynb`: Advanced BigQuery object referencing and AI/ML integration examples

### ğŸ¤– Agents
Python-based agents for intelligent contract analysis:
- `main.py`: FAST API app which exposes SEC Agent that queries BigQuery data using AI/ML functions and BigQuery Toolset

### ğŸŒ Web App
React-based frontend for interacting with AI agents:

<div align="center">
  <img src="assets/Webapp Query Documents.png" alt="Web App - Document Querying" width="700"/>
  <p><em>Document Querying Interface</em></p>
</div>

<div align="center">
  <img src="assets/WebApp AI.GENERATE_TABLE.png" alt="Web App - AI Table Generation" width="700"/>
  <p><em>AI-Powered Table Generation</em></p>
</div>

Key components:
- `src/components/ChatMessage.tsx`: Chat message display component
- `src/services/chatApi.ts`: API service for communicating with backend agents

## ğŸ› ï¸ Installation

This project uses [uv](https://github.com/astral-sh/uv) for fast Python package management.

### Prerequisites
- Install uv: `curl -LsSf https://astral.sh/uv/install.sh | sh`

### Setup
```bash
# Create virtual environment and install dependencies
uv sync

# Activate the virtual environment
source .venv/bin/activate  # On Unix/macOS
# or
.venv\Scripts\activate     # On Windows
```

### Development Setup
```bash
# Install development dependencies
uv sync --group dev

# Install documentation dependencies
uv sync --group docs
```

## ğŸš€ Usage

Add your Google Cloud credentials and API keys to a `.env` file:

```env
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json
GOOGLE_CLOUD_LOCATION='your-project-location'
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ sec-filings/
â”‚       â”œâ”€â”€ agent.py
â”‚       â””â”€â”€ prompts/
â”‚           â””â”€â”€ root_agent_prompt.py
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatContainer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ChatMessage.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ chatApi.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ chat.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ BQ-MCC-EXPLORATION.ipynb
â”‚   â”œâ”€â”€ ObjectRef.ipynb
â”‚   â””â”€â”€ examples/
â”‚       â”œâ”€â”€ analyze_multimodal_data_bigquery.ipynb
â”‚       â””â”€â”€ bigquery_generative_ai_intro.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ingestion/
â”‚       â”œâ”€â”€ extraction.py
â”‚       â”œâ”€â”€ contract_schema.py
â”‚    
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```
